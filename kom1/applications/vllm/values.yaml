vllm:
  servingEngineSpec:
    runtimeClassName: ""
    modelSpec:
      - name: "opt125m"
        repository: "vllm/vllm-openai"
        tag: "latest"
        modelURL: "facebook/opt-125m"

        replicaCount: 1

        requestCPU: 1
        requestMemory: "16Gi"
        requestGPU: 1

        nodeSelectorTerms:
          - matchExpressions:
              - key: nvidia.com/vgpu.present
                operator: "In"
                values:
                  - "true"

    tolerations:
    - key: "node-role.kubernetes.io/gpu"
      operator: "Exists"
